
# <center> Проект_1. Анализ резюме на сайте HeadHunter.</center>

## Оглавление  
[:one: Описание проекта](#arrow_forward-описание-проекта)  
[:two: Организационная информация](#arrow_forward-организационная-информация)  
[:three: Этапы работы над проектом](#arrow_forward-этапы-работы-над-проектом)  
[:four: Результат](#arrow_forward-результат)        
[:five: Установка проекта](#arrow_forward-установка-проекта)   
[:six: Авторы](#arrow_forward-авторы)  
[:seven: Выводы](#arrow_forward-выводы)  


### :arrow_forward: Описание проекта    
В вашем распоряжении база резюме, выгруженная с сайта поиска вакансий hh.ru.

Проблематика: часть соискателей не указывает желаемую заработную плату, когда составляет своё резюме.

Компания HeadHunter хочет построить модель, которая бы автоматически определяла примерный уровень заработной платы, подходящей пользователю, исходя из информации, которую он указал о себе. Задача заключается в обработке и анализе этих данных!

:arrow_up: [к оглавлению](#оглавление)

**О структуре проекта:**
* [HH_project](/HH_project/) - папка с основными файлами проекта
* [Plotly_png](/HH_project/Plotly_png/) - папка с изображениями, необходимыми для проекта
* [HTML_graph](/HH_project/HTML_graph/) - папка с HTML-файлами, графиков
* [requirements.txt](/HH_project/requirements.txt) - код воспроизводим: зафиксированы версии библиотек в виде файла requirements.txt или иного формата файлов конфигураций.
* [HH_project.ipynb](/HH_project/HH_Project.ipynb) - jupyter-ноутбук, содержащий основной код проекта.
* [head_hunter.py](HH_project/head_hunter.py) - Python - файл, содержащий код проекта

**Условия задачи:**  
> Представлен датасет, содержащий в себе информацию в виде резюме кандидатов. Задача заключается в уяснении структуры данных, приведении данных к необходимому формату, выявлении зависмостей путем построения графиков, очистке данных.

**Метрика качества**     
Результат оценивается по количестуству и качеству представленных ответов.

**Что практикуем**     
Практикуем работу с библиоетками Pandas, Plotly, Matplotlib, Seaburn, Numpy.


**Краткая информация о данных**

Данные представлены в виде датасета состоящего из 44744 строк и 12 столбцов.
  
:arrow_up: [к оглавлению](#оглавление)

### :arrow_forward: Организационная информация

При работе над проектом использовались следующие библиотеки:
1. Pandas
2. Plotly
3. Matplotlib
4. Seaborn
5. Numpy

### :arrow_forward: Этапы работы над проектом  

Работа над проектом состоит из четырёх частей:

1. Исследование структуры данных
2. Преобразование данных
3. Исследование зависимостей в данных
4. Очистка данных

:arrow_up: [к оглавлению](#оглавление)


### :arrow_forward: Результат:  

В результате работы, сделаны необходимые преобразования, построены графики зависимостей (с предпологаемыми выводами),  очищены данные.

### :arrow_forward: Установка проекта

```
git clone https://github.com/Esserpiente/HH_project
```

Внимание: так как основное датасет большого размера, скачать его можно по [ссылке.](https://disk.yandex.ru/d/xPERc_CujlsKdg)

### :arrow_forward: Авторы
 
 Алексей Александрович

### :arrow_forward: Выводы

По результатам выполнения проекта приобретены необходимые навыки в базовом анализе структуры данных, преобразовании данных, исследовании зависимостей в данных и их очистке.

:arrow_up: [к оглавлению](#оглавление)